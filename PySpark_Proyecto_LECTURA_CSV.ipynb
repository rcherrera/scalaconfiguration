{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc55974f",
   "metadata": {},
   "source": [
    "# ðŸš€ PySpark - Lectura de CSV\n",
    "Este cuaderno crea una `SparkSession` y carga el archivo `datasets/vgsales.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configurar JAVA_HOME y SPARK_HOME si es necesario\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Microsoft\\\\jdk-11.0.16.101-hotspot\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\\\spark-3.4.4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba10508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LecturaCSV\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… SparkSession iniciada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c838f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer archivo CSV desde la carpeta datasets/\n",
    "df = spark.read.csv(\"datasets/vgsales.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Mostrar los primeros registros\n",
    "df.show(5)\n",
    "\n",
    "# Ver el esquema del DataFrame\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
